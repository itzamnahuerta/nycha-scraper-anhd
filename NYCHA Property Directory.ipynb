{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00e8f4e",
   "metadata": {},
   "source": [
    "## NYCHA Property Directory Block and Lot Guide Parser\n",
    "**Developed by**: Itzamna Huerta, for the Association for Neighborhood and Housing Development (ANHD)  \n",
    "**Created**: September 2024  \n",
    "**Last Updated**: N/A  \n",
    "\n",
    "---\n",
    "\n",
    "### Overview:\n",
    "\n",
    "This Python script extraacts and processes data from the NYCHA Property Directory Block and Lot Guide PDF, making it more clear for internal purposes at ANHD [JustFixNYC’s NYCHA Scraper](https://github.com/JustFixNYC/nycha-scraper/tree/master). Using **pdfplumber** for table extraction and **pandas** for organizing data, the script cleans and structures PDF data for easier analysis. It resolves issues like irregular row lengths and missing information. \n",
    "\n",
    "The script’s primary functionality includes handling complex multi-page tables, automatically tagging rows with the correct **borough**, and identifying \"bad\" rows (those that don't meet the expected structure), ensuring accurate borough data association across the entire dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Enhanced Data Processing**: Improves JustFixNYC’s JavaScript approach by handling more complex data structures and errors.\n",
    "- **Error Handling**: Separates and cleans rows that don’t match the expected format.\n",
    "- **Borough Categorization**: Ensures each row is labeled with its borough.\n",
    "\n",
    "---\n",
    "\n",
    "### Methodology:\n",
    "1. **Borough Detection**: Scans each page to identify its borough and appends it to the data.\n",
    "2. **PDF Processing**: Extracts and separates valid and invalid rows based on their structure (8 columns expected).\n",
    "3. **Data Cleaning**: Cleans valid rows by removing unnecessary data and formatting errors, while also cleaning invalid rows for potential use.\n",
    "4. **Final Output**: Merges cleaned data and exports it to a CSV for further analysis.\n",
    "\n",
    "\n",
    "Final Output: Merges cleaned data and exports it to a CSV for further analysis.\n",
    "---\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "# Process the PDF and obtain the dataframes\n",
    "combined_df, bad_rows_df = process_pdf_to_dataframe('./2024/Block-and-Lot-Guide-2024.pdf')\n",
    "\n",
    "# Export to CSV for further analysis\n",
    "combined_df.to_csv('NYCHA_Valid_Data.csv', index=False)\n",
    "bad_rows_df.to_csv('NYCHA_Bad_Rows.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91085d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ac18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath name\n",
    "pdf_path = \"./2024/Block-and-Lot-Guide-2024.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5c00d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages: 85\n"
     ]
    }
   ],
   "source": [
    "# Define Functions and Process the PDF\n",
    "def extract_borough_from_text(full_text):\n",
    "    '''Extracts the borough name from the full text of a PDF page.'''\n",
    "    boroughs = [\"MANHATTAN\", \"BROOKLYN\", \"QUEENS\", \"BRONX\", \"STATEN ISLAND\"]\n",
    "    for borough in boroughs:\n",
    "        if borough in full_text:\n",
    "            return borough\n",
    "    return None\n",
    "\n",
    "def process_pdf_to_dataframe(pdf_path):\n",
    "    '''Processes the PDF file and returns a combined DataFrame with borough info and a DataFrame of bad rows.'''\n",
    "    all_tables_df = []\n",
    "    all_bad_rows = []\n",
    "\n",
    "    # Open the PDF file\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        total_pages = len(pdf.pages)\n",
    "        print(f\"Total number of pages: {total_pages}\")\n",
    "\n",
    "        # Process each page of the PDF\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # You can uncomment to see the progress of each page\n",
    "            # print(f\"Processing page {i+1} of {total_pages}\")\n",
    "            \n",
    "            # Extract borough from the full text\n",
    "            full_text = page.extract_text()\n",
    "            borough = extract_borough_from_text(full_text)\n",
    "\n",
    "            if borough is None:\n",
    "                print(f\"No borough found on page {i+1}. Skipping.\")\n",
    "                continue  # Skip if no borough is found\n",
    "\n",
    "            # Extract tables from the page\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            # Process each table on the page\n",
    "            for table_index, table in enumerate(tables):\n",
    "                # Skip empty tables\n",
    "                if not table:\n",
    "                    print(f\"Table {table_index + 1} on page {i+1} is empty after processing.\")\n",
    "                    continue\n",
    "\n",
    "                # Append borough information to bad rows if any row doesn't match the expected length\n",
    "                for row in table:\n",
    "                    if len(row) != 8:  # Expected length is 8, adjust if different\n",
    "                        row.append(borough)  # Add the borough to the row as the last column\n",
    "                        all_bad_rows.append(row)  # Collect bad rows\n",
    "\n",
    "                # Check if valid table rows (i.e., with expected column length)\n",
    "                valid_rows = [row for row in table if len(row) == 8]\n",
    "                if valid_rows:\n",
    "                    # Append borough information to each valid row\n",
    "                    for row in valid_rows:\n",
    "                        row.append(borough)  # Add borough to valid rows\n",
    "                    \n",
    "                    # Create a DataFrame from the valid rows\n",
    "                    df = pd.DataFrame(valid_rows)\n",
    "                    all_tables_df.append(df)\n",
    "\n",
    "    # Combine all valid DataFrames into a single DataFrame\n",
    "    if all_tables_df:\n",
    "        combined_df = pd.concat(all_tables_df, ignore_index=True)\n",
    "    else:\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "    # Create a DataFrame for bad rows\n",
    "    if all_bad_rows:\n",
    "        # Create DataFrame from bad rows, ignoring column names and just adding the borough at the end\n",
    "        bad_rows_df = pd.DataFrame(all_bad_rows)\n",
    "    else:\n",
    "        bad_rows_df = pd.DataFrame()\n",
    "\n",
    "    return combined_df, bad_rows_df\n",
    "\n",
    "# Run the function\n",
    "combined_df, bad_rows_df = process_pdf_to_dataframe(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791673e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Additional data cleaning for combined_df\n",
    "#####\n",
    "\n",
    "# Set the first row as the header\n",
    "combined_df.columns = combined_df.iloc[0]\n",
    "\n",
    "# Drop the first row (now the header)\n",
    "combined_df = combined_df[1:].reset_index(drop=True)\n",
    "\n",
    "# Update header name from BRONX to BOROUGH \n",
    "combined_df.rename(columns = {'BRONX':'BOROUGH'}, inplace = True)\n",
    "\n",
    "# Replace all instances of \\n within any column in the dataframe\n",
    "combined_df.replace('\\n', ' ', regex=True, inplace=True)\n",
    "\n",
    "# There are 8 rows where this condition is met. We are going to update the dataset by removing those rows.\n",
    "combined_df = combined_df[~combined_df['BLOCK'].str.contains('BLOCK', na=False)]\n",
    "\n",
    "# Remove rows where 'ADDRESS' is empty, these could be parking lots, air rights, etc. \n",
    "combined_df = combined_df[combined_df['ADDRESS'] != '']\n",
    "\n",
    "# Convert 'BLOCK' to int64, replacing non-convertible cells with 0\n",
    "combined_df['BLOCK'] = pd.to_numeric(combined_df['BLOCK'].str.strip(), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Drop rows where 'BLOCK' contains 0\n",
    "combined_df = combined_df[combined_df['BLOCK'] != 0]\n",
    "\n",
    "# Remove rows where 'ZIP CODE' is empty, it's either vacant land, parking lot, development grounds, etc.\n",
    "combined_df = combined_df[combined_df['ZIP CODE'] != '']\n",
    "\n",
    "# This approach first replaces empty strings with 0, converts the column to float, fills any NaN values, and finally converts to int.\n",
    "combined_df['CD#'] = pd.to_numeric(combined_df['CD#'].replace('', '0'), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Remove CD's that equal 0, these 2 records are development grounds\n",
    "combined_df = combined_df[combined_df['CD#'] != 0]\n",
    "\n",
    "# Update following columns to int\n",
    "combined_df[['LOT', 'ZIP CODE', 'CD#']] = combined_df[['LOT', 'ZIP CODE', 'CD#']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0312b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "BLOCK           int64\n",
       "LOT             int64\n",
       "ADDRESS        object\n",
       "ZIP CODE        int64\n",
       "DEVELOPMENT    object\n",
       "MANAGED BY     object\n",
       "CD#             int64\n",
       "FACILITY       object\n",
       "BOROUGH        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986c50e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>DEVELOPMENT</th>\n",
       "      <th>MANAGED BY</th>\n",
       "      <th>CD#</th>\n",
       "      <th>FACILITY</th>\n",
       "      <th>BOROUGH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2215</td>\n",
       "      <td>116</td>\n",
       "      <td>5210 BROADWAY</td>\n",
       "      <td>10463</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>8</td>\n",
       "      <td>ROOFTOP LEASE LOCATION</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2215</td>\n",
       "      <td>116</td>\n",
       "      <td>5220 BROADWAY</td>\n",
       "      <td>10463</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>8</td>\n",
       "      <td>DEVELOPMENT MANAGEMENT OFFICE</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2215</td>\n",
       "      <td>116</td>\n",
       "      <td>5470 BROADWAY</td>\n",
       "      <td>10463</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>8</td>\n",
       "      <td>CHILDREN CENTER</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2215</td>\n",
       "      <td>116</td>\n",
       "      <td>5480 BROADWAY</td>\n",
       "      <td>10463</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>8</td>\n",
       "      <td>NURSERY SCHOOL</td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2215</td>\n",
       "      <td>116</td>\n",
       "      <td>5360 BROADWAY</td>\n",
       "      <td>10463</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>MARBLE HILL</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>BRONX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  BLOCK  LOT        ADDRESS  ZIP CODE  DEVELOPMENT   MANAGED BY  CD#  \\\n",
       "0   2215  116  5210 BROADWAY     10463  MARBLE HILL  MARBLE HILL    8   \n",
       "1   2215  116  5220 BROADWAY     10463  MARBLE HILL  MARBLE HILL    8   \n",
       "2   2215  116  5470 BROADWAY     10463  MARBLE HILL  MARBLE HILL    8   \n",
       "3   2215  116  5480 BROADWAY     10463  MARBLE HILL  MARBLE HILL    8   \n",
       "4   2215  116  5360 BROADWAY     10463  MARBLE HILL  MARBLE HILL    8   \n",
       "\n",
       "0                       FACILITY BOROUGH  \n",
       "0         ROOFTOP LEASE LOCATION   BRONX  \n",
       "1  DEVELOPMENT MANAGEMENT OFFICE   BRONX  \n",
       "2                CHILDREN CENTER   BRONX  \n",
       "3                 NURSERY SCHOOL   BRONX  \n",
       "4                                  BRONX  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f91042a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Further data cleaning for the bad rows in order to merge it with the combined_df \n",
    "\n",
    "pd.options.display.max_rows=2000\n",
    "\n",
    "# Rename the columns\n",
    "bad_rows_df.rename(columns={ 0: 'BLOCK', \n",
    "                             1: 'LOT', \n",
    "                             2: 'ADDRESS', \n",
    "                             3: 'TO_BE_DELETED_1',\n",
    "                             4: 'ZIP CODE',\n",
    "                             5: 'DEVELOPMENT',\n",
    "                             6: 'TO_BE_DELETED_2',\n",
    "                             7: 'MANAGED BY',\n",
    "                             8: 'CD#',\n",
    "                             9: 'FACILITY',\n",
    "                             10: 'BOROUGH'\n",
    "                            }, inplace=True)\n",
    "\n",
    "bad_rows_df.drop(columns=['TO_BE_DELETED_1', 'TO_BE_DELETED_2'], inplace=True)\n",
    "\n",
    "# header_bad_rows = bad_rows_df[bad_rows_df['BLOCK'].str.contains('BLOCK', na=False)]\n",
    "# header_bad_rows.shape\n",
    "# Result: (76, 9), plus the 8 found in the combined_df is 84 which is expected\n",
    "\n",
    "# There are 76 rows where this condition is met. We are going to update the dataset by removing those rows.\n",
    "bad_rows_df = bad_rows_df[~bad_rows_df['BLOCK'].str.contains('BLOCK', na=False)]\n",
    "\n",
    "# Replace all instances of \\n within any column in the dataframe\n",
    "bad_rows_df.replace('\\n', ' ', regex=True, inplace=True)\n",
    "\n",
    "# Convert 'BLOCK' to int64, replacing non-convertible cells with 0\n",
    "bad_rows_df['BLOCK'] = pd.to_numeric(bad_rows_df['BLOCK'].str.strip(), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Drop rows where 'BLOCK' contains 0\n",
    "bad_rows_df = bad_rows_df[bad_rows_df['BLOCK'] != 0]\n",
    "\n",
    "# Remove rows where 'ZIP CODE' is empty, it's either vacant land, parking lot, development grounds, etc.\n",
    "bad_rows_df = bad_rows_df[bad_rows_df['ZIP CODE'] != '']\n",
    "\n",
    "# This approach first replaces empty strings with 0, converts the column to float, fills any NaN values, and finally converts to int.\n",
    "bad_rows_df['CD#'] = pd.to_numeric(bad_rows_df['CD#'].replace('', '0'), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Remove CD's that equal 0, these 2 records are development grounds\n",
    "bad_rows_df = bad_rows_df[bad_rows_df['CD#'] != 0]\n",
    "\n",
    "# Update following columns to int\n",
    "bad_rows_df[['LOT', 'ZIP CODE', 'CD#']] = bad_rows_df[['LOT', 'ZIP CODE', 'CD#']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd32b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLOCK           int64\n",
       "LOT             int64\n",
       "ADDRESS        object\n",
       "ZIP CODE        int64\n",
       "DEVELOPMENT    object\n",
       "MANAGED BY     object\n",
       "CD#             int64\n",
       "FACILITY       object\n",
       "BOROUGH        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_rows_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c84c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcf390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the bad batch with combined_df \n",
    "merged_df = pd.concat([combined_df, bad_rows_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fff51250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLOCK           int64\n",
       "LOT             int64\n",
       "ADDRESS        object\n",
       "ZIP CODE        int64\n",
       "DEVELOPMENT    object\n",
       "MANAGED BY     object\n",
       "CD#             int64\n",
       "FACILITY       object\n",
       "BOROUGH        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a97605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired order of columns\n",
    "desired_order = ['BOROUGH', 'BLOCK', 'LOT', 'ADDRESS', 'ZIP CODE', 'DEVELOPMENT', 'MANAGED BY', 'CD#', 'FACILITY']\n",
    "\n",
    "# Rearranging the columns\n",
    "merged_df = merged_df[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15865e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataset to a csv for further comparison \n",
    "merged_df.to_csv('./2024/Block-and-Lot-Guide-01012024-ANHD.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python31012jvsc74a57bd0bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
